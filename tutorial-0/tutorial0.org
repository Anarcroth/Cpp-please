#+OPTIONS: num:nil toc:nil
#+REVEAL_ROOT: file:///home/mdn/reveal.js-3.6.0
#+REVEAL_TRANS: slide
#+REVEAL_THEME: moon
#+Title: C++ a more in depth look into the language
#+Author: Martin Nestorov
#+Email: mdn150@aubg.edu / @mdnestorov

* Who am I?  

    - Martin Nestorov
    - Junior 2nd sem.
    - I like to type . . . a lot
    - email: mdn150@aubg.edu
    - Twitter: @mnestorov

* Why I chose to make these small tutorials

  - People seem to have some problems with the transition from C++ to FDS.
  - I want to help!
  - I want to also learn!

#+BEGIN NOTES:

  Over the course of the past several years I found a certain love for C++, but instead of just reading about the language and doing some small experiments with it,   I wanted to share my knowledge and to get better at it. Seeing how some students struggle with C++ in the beginning courses, I decided that I can help out. That way not only am I learning more in-depth concepts, but also I am making the lives of students easier (hopefully).

#+END NOTES

* How to look at C++

  C++ as four sub-languages
  - C
  - OOP
  - STL
  - Templates

#+BEGIN NOTES:

  C++ can be generally divided into four sub-categories or sub-languages.
  It's a daunting task to go over all of these aspects and trying to teach everything, mainly because I can't! But instead I will try to cover some topics
  that haven't been covered in depth in the C++ lectures and are somewhat elude to the students. Now our list seems like this

#+END NOTES

* What we are going to cover

  - File structure
  - Memory management
  - Templates
  - Inheritance
  - OOP
  - STL

* File structure

#+BEGIN NOTES:

  It has come to my attention that many people, while writing their homeworks, neglect the advantages of structuring their **source** files. This is most noticeable when they are writing the first 3 FDS homeworks or their FDS project. Being able to properly manage your project into several files and to navigate between them in an optimal and cohesive way will minimize your C++ suffering (and coding experience in general).

  Now most of you already know this, but there are several great advantages to separating your *implementation* (cpp) files from your *definition* (h) files. One such advantage is that, multiple people can start working on several *header* files and instead of you waiting for them to be ready, you can continue with your work while they finish theirs. This separation of implementation is important, because it minimizes development time. But because you will be working mostly alone with your solutions, you will see another great advantage of structuring your files, and that is - it will be much easier for you to understand what you are doing and thus will minimize debugging and problem fixing time.

  Since most of you are working with Visual Studio, here is how your structure looks like now:
Picture 1

  And here is how you would want it to look.
Picture 2

  Now I am not going to tell you how to add files and where to put them, I will just show you how to properly implement header and source files and how to avoid collisions and also how to stop writing those damn "xfz.h" files.

  First things first.

  What's the difference between headers and sources? Apart from the obvious name difference, header files are considered to be the *definition* part of the source code, while source (cpp) files are the *implementation* part. Keeping them separate allows us to keep a clean directory and structure and to separate our logic from our implementation.

#+END NOTES

* How does compilation work?

  There are 3 steps of compiling C++ code:
  - Preprocessing
  - Compilation
    - Compilation
    - Assembly
  - Linking

#+BEGIN NOTES:

  When we are trying to run a piece of code (in our case C++), the computer goes through several steps before we see the output, or the errors. 

  The first part is the so called **preprocessing** step, where the *preprocessor* handles the `preprocessor` *directives*. These are the `#include`, `#define`, `#if`, `#ifndef`, `#ifdef` keywords we put on the top of our files. At this stage, one file at a time, each of these *directives* are replaces with their respective pieces of code from other files (they are usually only declarations). That is why when we have multiple source files, we include only the header files, because they only show us the declarations and not the definitions (thus we minimize time in this step). So after the directives have been replaced with the respective file contents or snippets of files (depending in the `#if` `#ifndef` and `#ifdef` and the macro `#define` keywords) we get at the end "pure C++" code. The preprocessor also adds line numbers so that the further steps can identify where the inserted code came from. As an example, if we write `#include <iostream>` we actually just insert the contents from the `iostream` library on the top of our main source file (again we must remember that most of the time, we are just including declarations).

  As a side note, this whole process is very similar for C code as well.

  So at the end of all of this copying, we get a temporary file that is just C/C++ code. It's indicated by the `*.i` or `*.ii` file extension, meaning that this file is just C/C++ code and must not be preprocessed.

  We must note that the preprocessor is agnostic to the C++ syntax, that is why for instance, in Visual Studio we have the `#pragma` directive that tries to do the `#ifndef` directive work, but that's just a lie. 

  We have to be careful where and how we put our *includes*.

  **Tip:** one of the things we want to do while writing C++ code is to minimize our reliance on the preprocessor. That is, if we are `#define`-ning macros as constants so that we can use them throughout our program, we might encounter strange errors, because these directives may be treated as not part of the language. As an example, if we write `#define A_RATIO 1.18` the preprocessor might skip the name and just include the double 1.18. Then if we get, or when we get, an error referring to 1.18, we might not know it's because it was a macro define lost from the preprocessor. Instead we can just use `const`s as such: `const double ARatio = 1.18;` Now we know that the compiler will see this variable and we won't bang our head against the wall with unnecessary errors.

  In order to get only the preprocessed file we can run the
  `g++ -E hello-world.cpp -o hello-world.ii`
  which will produce the `hello-world.ii` file and then we can look inside of it and find out what it includes.

  After we have our "pure C++" code (ending with the `*.i/*.ii`) suffix, we are ready to move to the next step - *Compilation*.

---

  The **compilation** step is another relatively simple phase, where the preprocessed pure C++ file is transformed into *assembly* code. From there the compiler invokes an underlying back-end (assembler tool-chain) and assembles the assembly code into *machine* code, thus producing an actual *binary file* (where there are different binary file formats such as: `EFL`, `a.out`, `COFF`, `SOM`). This is the so called *object file*, which contains the compiled code into binary form of the symbols defined in the input. This file is usually no directly executable. The object files also contain additional data in the form of sections, used for linking, debugging, symbolic cross-reference resolution, comments, re-allocations, program symbols, etc (sections can be `.text`, `.bss`, `.data`, `.reloc`, etc.). The object files contain the metadata that hold the memory locations (addressed) of the variables and functions (called symbols) into an associative data structure called a *symbolic table*. Note that these addresses might not be the final addresses of the symbol in the final executable. The things that might be interesting to us is the symbol table. This is a data structure in the object file that's basically a name and an index. It maps different items in the object file to names that the linker can understand. If you call a function from your code, the compiler doesn't put the final address of the routine in the object file. Instead, it puts a placeholder value into the code and adds a note that tells the linker to look up the reference in the various symbol tables from all the object files it's processing and stick the final location there.

  To get the object file we can run
  
  `g++ -c hello-world.ii`
  
  or
  
  `g++ -c hello-world.cpp`
  
  and we can then look inside what an object file looks like with
  
  `nm hello-world.o`
  
  or
  
  `objdump -t hello-world.o`

  One big advantage to this is that the *compiler* can stop the compilation at this phase. Because you won't need to re-compile every file, but only those that *have been* changed, you can specify which files to compile and save time. **IDEs** and some other tools can do this automatically and check the timestamps of the files and only compile those source codes which have been modified. On the compilation step we get the normal compiler errors, such as *syntax errors*, *failed function overload errors*, etc.

  Once we have the object file we can transform it into special *executables*, *shared*, or *dynamic* libraries. Here the *linker* comes into play.

---

  The **linker** just links all of the object files into one executable file. The just of it is that the linker *links* object files by resolving undefined definitions of functions in the object files. That is, it goes through the object files and for every undefined function it tries to replace the reference of the undefined symbol with the correct address in another object file or in the standard library. The whole linking process is somewhat tedious and difficult to follow as it involves moving memory locations and relocation of symbols so we can skip this part, but for those who are interested, there are several links that explain exactly how the linker does its job.

  One thing that we will encounter are the terms **dynamic** and **static** linking. *Static* linking is the process that links the program and the libraries together at normal link time. This means that the binding between the program and the library is known at link time. We are linking the program statically to a *shared archive* of objects (libraries). An example would be the standard `libc.a` library for **C**. A draw back to this approach is that the size of the executable is quite big, because everything must be bundled together. These static libraries are identified by the `*.a` file extension.

  Although the deployment of such *executables* is much easier and allows us to have *0 dependencies*, the size of the binary can get too big and such static linkage does not allow us to reuse memory for executable code between different processes. What this means is that when we have multiple executables that rely on the same library, unless our OS is very smart, it's very likely that we are loading the same piece of code over and over, incrementally increasing the memory we are using for the same piece of code. Another problem is that if we are to change something and have to *re-build* and *run* the executable, we would spend a lot of time reallocating with the static library.

  To overcome this problem we can use **dynamic** libraries. For the Windows users, these are the famous `*.dll` files. In essence, we get an *incomplete* binary, which is told *during* runtime, where to search for the code in the respective library. That is - the linkage of the functions from the shared objects and our program is done during runtime right before the program starts. The linker just mentions to the executable that there is a function from a shared object used at this particular place and notes it in the binary, and then carries on. The symbols of the shared objects (the ones in the libraries we are using) are only verified and validated that they exist, but are not combined into the final executable binary. Thus we get several great advantages to using dynamic linking and libraries:
  - Portable executables with smaller size.
  - Standard libraries can be updated and re-patched without the need of re-linkage of every program.
  - We can run multiple processes that use the same shared libraries without the need of copying the same code, thus saving large amounts of memory space.

  This is the last step before we can take the `.exe` file, load it into memory and run it. At the linking stage we get different errors, such as *multiple function definitions*, or *undefined functions*, *missing references*, etc.

  **Loading and running** - Now that we have a ready executable file we just have to *load* it into memory and run it. The **loader** is a general part of the OS and it operates in several steps. The general idea is this - first we validate memory and access privileges to the exe. The OS reads the header of our binary, checks if we have enough space to run the program, checks what kind of access permissions we have, checks the ability to run the instructions, makes sure that this is a valid executable image, and then goes through several steps of loading. To be exact - it allocates primary memory to run the file, copies the address spaces from secondary to primary memory, copies the multiple sections of the executable to the primary memory, copies the command line arguments on to the stack, refreshes the register and re-points the **esp** (the stack pointer) to the top of the cleared stack, and finally jumps to the start of the program and runs the `main()` method.

---

  **Conclusion** - we can see that this is somewhat of a long process, where a lot of steps take place. This is done, from one point of view, for easier implementation and reduction of complexity. Being able to control all of these functionalities allows us to create big programs, to compile them in an easy and fast manner, and to understand what kind of errors we are getting at what stage. With the powers of "conditional compilation" we are able to create pre-compiled libraries that need only linking, this is called a "separate compilation model". Knowing the difference between the compilation phase and the link phase can make it easier to hunt for bugs. Compiler errors are usually syntactic in nature -- a missing semicolon, an extra parenthesis. Linking errors usually have to do with missing or multiple definitions. If you get an error that a function or variable is defined multiple times from the linker, that's a good indication that the error is that two of your source code files have the same function or variable. 

#+END NOTES

* Memory layout

  The memory layout can be divided into *five* sections:
  - text
  - data
  - bss
  - stack
  - heap

#+BEGIN NOTES:

  The different segments in memory are the text, data, bss, stack, and heap.
  
  The text segment holds the executable instructions inside. The OS tries to make is so that if the same program is running on multiple instances, this part of the code is shared between the individual processes, instead of being copied multiple times.

  The data segment is where the non zero initialized global and statically allocated variables are. Each running instance of the program has an individual segment holding this piece of data.

  The bss segment (Block Started by Symbol) is where all of the zero initialized global and statically allocated variables are. Again, each running instance has an individual bss segment. While running the bss segment is stored in the data segment, but in the execution file it is stored in the bss section.

  The heap is the dynamic part of the memory allocation (C uses `malloc()`, `calloc()`, and `realloc()`, while C++ has `new`). Everything in this part of the memory is anonymous and needs a pointer to gain access to it. When we allocate new memory the process address space grows upwards. This means that as new items are added, the addresses of those items are numerically greater than the addresses of the previous ones. To free up memory from the heap we use `free()` for C and `delete` for C++, thus leaving holes in the memory. This means that when you are allocating objects to the heap and then deleting them, because of their different size, you might get into the situation where some deleted object free up space between objects that are still on the heap. Thus physically leaving free space that cannot be used by larger objects. This is the idea of leaving holes. 
  
  We can picture it as if we have a blank wall and then start arranging pictures on it. If we are not careful with our picture arrangement we might get most of the pictures on the wall, but at some point we might get small free spaces that are just blank wall. Thus we technically do have space for more pictures, but this space is fragmented and unusable for bigger pictures (presuming that we cannot chop up our pictures into pieces). This is the same with the memory allocation and de-allocation on the heap. On our machines, where we have virtual memory, we don't really experience this problem, because it is important for the virtual memory to have the object into one continuous block. We can experience this problem of memory fragmentation when we start getting allocation errors (such as `malloc()` returning `null`, or when we cannot free up memory properly, or when our program takes too long to reallocate memory.
  To overcome this problem we might use some tactical position of object creation to avoid such problems. We can allocate objects from different areas according to their size and/or their expected lifetime. So if you're going to create a lot of objects and destroy them all together later, allocate them from a memory pool. Any other allocations you do in between them won't be from the pool, hence won't be located in between them in memory, so memory will not be fragmented as a result (Using a good algorithm for allocating memory, we can, instead of allocating memory for a lot of small objects, pre-allocate memory for a contiguous array of those smaller objects. Sometimes being a little wasteful when allocating memory can go along way for performance and may save you the trouble of having to deal with memory fragmentation).

  In general we don't have to worry that much for this sort of fragmentation unless our program is long running and has a wide mixture of long lived/short lived, big/small objects that are constantly created and destroyed. But even then the automatic memory allocation is on our side and helps us as much as it can. So we can start worrying about this only when we see clear sings of slow processes and blatant memory errors.

  The great thing about C++ is that the STL handles these allocations very well and it's optimized so if we are relying on the STL (and we should), then we wouldn't have any problems.

  The end of the heap is indicated by the `break` pointer. It is impossible to allocate more data beyond this range, but with system calls `brk()` and `sbrk()` we can move the break further up the memory and free up more space for our running program (keep in mind that such direct system calls are generally a bad practice and should be avoided).

  The stack is the static part of the memory allocation in our program. Here local variables are allocated. These are all the variables that are declared inside a function body and are not set as `static`. Following the stack data structure, local variables, function parameters, addresses, etc. are popped up or pushed down for quick and easy access.

  When a function is called a stack frame (a procedure activation record) is pushed on top of the stack. A stack frame holds information for the address from where the function was called, where to jump back when the function ends (return address), local variables, function parameters, and any other information needed by the function. When the function returns, the stack frame is popped from the top of the stack. The stack grows downwards, meaning that the address of each stack frame is numerically smaller than the previous one.

  So when a program is running, the data, bss, and heap segments are aligned into one continuous memory block (area) called a data segment. The stack is kept separate from them. In theory it is possible for the stack and heap to collide and grow inside each other, but the OS prevents such collisions.

#+END NOTES

  This is all the space and data the program needs in order to run properly.

  `$$ address space = memory space $$`

* References
  **Preprocessing, Compilation, and Linking**
	- https://en.wikipedia.org/wiki/Object_file
	- https://www.toptal.com/c-plus-plus/c-plus-plus-understanding-compilation
	- http://www.cplusplus.com/doc/tutorial/preprocessor/
	- https://stackoverflow.com/questions/6264249/how-does-the-compilation-linking-process-work
	- https://stackoverflow.com/questions/12122446/how-does-c-linking-work-in-practice/30507725#30507725
	- http://www.iecc.com/linker/
	- https://www.airs.com/blog/archives/38
	- http://www.cirosantilli.com/elf-hello-world/
	- https://stackoverflow.com/questions/3322911/what-do-linkers-do/33690144#33690144
	- http://faculty.cs.niu.edu/~mcmahon/CS241/Notes/compile.html
	- https://www.cprogramming.com/compilingandlinking.html
	- http://www.cplusplus.com/articles/2v07M4Gy/
	- http://www.tenouk.com/ModuleW.html
	- http://www.tenouk.com/Bufferoverflowc/Bufferoverflow1.html
	- http://nickdesaulniers.github.io/blog/2016/08/13/object-files-and-symbols/
	- http://nickdesaulniers.github.io/blog/2016/11/20/static-and-dynamic-libraries/ 
	- https://en.wikipedia.org/wiki/Object_file
	- https://stackoverflow.com/questions/3880924/how-to-view-symbols-in-object-files
	- https://stackoverflow.com/questions/69112/what-is-a-symbol-table
	- https://codeyarns.com/2014/08/07/how-to-list-symbols-in-object-file/

  **Memory management**
  - https://stackoverflow.com/questions/3770457/what-is-memory-fragmentation
	- http://www.tenouk.com/ModuleW.html
